{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeca5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fce879",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel (r'Fall2021_Perceptions_Explanations_All_Final.xlsx')\n",
    "df2 = pd.read_excel (r'Spring2022_Perceptions_Explanations_All_Final.xlsx')\n",
    "df = pd.concat([df1,df2])\n",
    "df = df[df[\"misplaced\"].isnull()]\n",
    "#df = df[df[\"explanation\"].notnull()]\n",
    "#df = df[df[\"explanation\"].isstr()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e11c16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa48be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_code_col(df_dum,code):\n",
    "    df_dum[code] = np.where(df_dum[\"code1\"] == code,1,0) + np.where(df_dum[\"code2\"] == code,1,0) + np.where(df_dum[\"code3\"] == code,1,0)+ np.where(df_dum[\"code4\"] == code,1,0)+ np.where(df_dum[\"code5\"] == code,1,0)\n",
    "    return df_dum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60769a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = define_code_col(df,\"CON\")\n",
    "df = define_code_col(df,\"EXT\")\n",
    "df = define_code_col(df,\"PER\")\n",
    "df = define_code_col(df,\"NAT\")\n",
    "df = define_code_col(df,\"MOT\")\n",
    "df = define_code_col(df,\"ANA\")\n",
    "df = define_code_col(df,\"PROB\")\n",
    "df = define_code_col(df,\"PLAN\")\n",
    "df = define_code_col(df,\"EXEC\")\n",
    "df = define_code_col(df,\"WRIT\")\n",
    "df = define_code_col(df,\"PART\")\n",
    "df = define_code_col(df,\"LEAD\")\n",
    "df = define_code_col(df,\"EXP\")\n",
    "df = define_code_col(df,\"HELP\")\n",
    "df = define_code_col(df,\"OTH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d1e3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>explanation</th>\n",
       "      <th>misplaced</th>\n",
       "      <th>code1</th>\n",
       "      <th>code2</th>\n",
       "      <th>code3</th>\n",
       "      <th>code4</th>\n",
       "      <th>code5</th>\n",
       "      <th>CON</th>\n",
       "      <th>EXT</th>\n",
       "      <th>...</th>\n",
       "      <th>ANA</th>\n",
       "      <th>PROB</th>\n",
       "      <th>PLAN</th>\n",
       "      <th>EXEC</th>\n",
       "      <th>WRIT</th>\n",
       "      <th>PART</th>\n",
       "      <th>LEAD</th>\n",
       "      <th>EXP</th>\n",
       "      <th>HELP</th>\n",
       "      <th>OTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lab</td>\n",
       "      <td>He has a great grasp of all of the different q...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CON</td>\n",
       "      <td>ANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lab</td>\n",
       "      <td>Their concepts are very strong and they always...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CON</td>\n",
       "      <td>PLAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lab</td>\n",
       "      <td>Focused on his work.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lab</td>\n",
       "      <td>Has great understanding of software to help an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lab</td>\n",
       "      <td>Works at air and space museum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>lecture</td>\n",
       "      <td>Strong grasp on the material and knows how to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CON</td>\n",
       "      <td>PROB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>lecture</td>\n",
       "      <td>Very Helpful and knowledgeable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HELP</td>\n",
       "      <td>CON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>lecture</td>\n",
       "      <td>very helpful and knowledgeable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HELP</td>\n",
       "      <td>CON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>lecture</td>\n",
       "      <td>very helpful and knowldgeable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HELP</td>\n",
       "      <td>CON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>lecture</td>\n",
       "      <td>very helpful and knowledgeable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HELP</td>\n",
       "      <td>CON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     context                                        explanation  misplaced  \\\n",
       "0        lab  He has a great grasp of all of the different q...        NaN   \n",
       "1        lab  Their concepts are very strong and they always...        NaN   \n",
       "2        lab                               Focused on his work.        NaN   \n",
       "3        lab  Has great understanding of software to help an...        NaN   \n",
       "4        lab                      Works at air and space museum        NaN   \n",
       "..       ...                                                ...        ...   \n",
       "698  lecture  Strong grasp on the material and knows how to ...        NaN   \n",
       "699  lecture                     Very Helpful and knowledgeable        NaN   \n",
       "700  lecture                     very helpful and knowledgeable        NaN   \n",
       "701  lecture                      very helpful and knowldgeable        NaN   \n",
       "702  lecture                     very helpful and knowledgeable        NaN   \n",
       "\n",
       "    code1 code2 code3 code4  code5  CON  EXT  ...  ANA  PROB  PLAN  EXEC  \\\n",
       "0     CON   ANA   NaN   NaN    NaN    1    0  ...    1     0     0     0   \n",
       "1     CON  PLAN   NaN   NaN    NaN    1    0  ...    0     0     1     0   \n",
       "2     MOT   NaN   NaN   NaN    NaN    0    0  ...    0     0     0     0   \n",
       "3     ANA   NaN   NaN   NaN    NaN    0    0  ...    1     0     0     0   \n",
       "4     EXT   NaN   NaN   NaN    NaN    0    1  ...    0     0     0     0   \n",
       "..    ...   ...   ...   ...    ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "698   CON  PROB   NaN   NaN    NaN    1    0  ...    0     1     0     0   \n",
       "699  HELP   CON   NaN   NaN    NaN    1    0  ...    0     0     0     0   \n",
       "700  HELP   CON   NaN   NaN    NaN    1    0  ...    0     0     0     0   \n",
       "701  HELP   CON   NaN   NaN    NaN    1    0  ...    0     0     0     0   \n",
       "702  HELP   CON   NaN   NaN    NaN    1    0  ...    0     0     0     0   \n",
       "\n",
       "     WRIT  PART  LEAD  EXP  HELP  OTH  \n",
       "0       0     0     0    0     0    0  \n",
       "1       0     0     0    0     0    0  \n",
       "2       0     0     0    0     0    0  \n",
       "3       0     0     0    0     0    0  \n",
       "4       0     0     0    0     0    0  \n",
       "..    ...   ...   ...  ...   ...  ...  \n",
       "698     0     0     0    0     0    0  \n",
       "699     0     0     0    0     1    0  \n",
       "700     0     0     0    0     1    0  \n",
       "701     0     0     0    0     1    0  \n",
       "702     0     0     0    0     1    0  \n",
       "\n",
       "[1009 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed3d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=0):\n",
    "  np.random.seed(seed)\n",
    "  random.seed(seed)\n",
    "  #tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9276a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm, linear_model, ensemble, neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "016476fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_kappa(tp,fp,fn,tn):\n",
    "    num = 2* (tp*tn - fn*fp)\n",
    "    denom = (tp+fp)*(fp+tn) + (tp+fn)*(fn+tn)\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48473ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word pre-processing here\n",
    "def preprocess_text(para):\n",
    "    # Remove punctuations and numbers\n",
    "    para = re.sub('[^a-zA-Z]', ' ', para)\n",
    "    # Single character removal\n",
    "    para = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', para)\n",
    "    # Removing multiple spaces\n",
    "    para = re.sub(r'\\s+', ' ', para)\n",
    "    \n",
    "    tokens = para.split()\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "Xt = []\n",
    "for response in df[\"explanation\"].tolist():\n",
    "    Xt.append(preprocess_text(response))\n",
    "    \n",
    "y = np.array(df[\"ANA\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72583bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split(s):\n",
    "    set_random_seed(seed=s)\n",
    "    Train_X, Test_X, Train_y, Test_y = model_selection.train_test_split(Xt,y,test_size=0.1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(Train_X)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(Train_X, mode=\"binary\")\n",
    "    # encode training data set\n",
    "    Xtest = tokenizer.texts_to_matrix(Test_X, mode=\"binary\")\n",
    "    return tokenizer, Xtrain, Xtest, Train_y, Test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48e3e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes1(s,tokenizer, Xtrain, Xtest, Train_y, Test_y):\n",
    "    set_random_seed(seed = s)\n",
    "    # fit the training dataset on the NB classifier\n",
    "    Naive = naive_bayes.MultinomialNB()\n",
    "    Naive.fit(Xtrain,Train_y)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_NB = Naive.predict(Xtest)\n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    #print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_y)*100)\n",
    "    #print(\"Naive Bayes Precision Score -> \",precision_score(predictions_NB, Test_y)*100)\n",
    "    #print(\"Naive Bayes Recall Score -> \",recall_score(predictions_NB, Test_y)*100)\n",
    "    # Confusion Matrix\n",
    "    #print(\"Naive Bayes Confusion Matrix -> \",confusion_matrix(predictions_NB, Test_y))\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions_NB, Test_y).ravel()\n",
    "    k = cohens_kappa(tp,fp,fn,tn)\n",
    "    return accuracy_score(predictions_NB, Test_y),precision_score(predictions_NB, Test_y),recall_score(predictions_NB, Test_y),k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dfe4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm1(s,tokenizer, Xtrain, Xtest, Train_y, Test_y):\n",
    "    set_random_seed(seed = s)\n",
    "    # Classifier - Algorithm - SVM\n",
    "    # fit the training dataset on the classifier\n",
    "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(Xtrain,Train_y)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_SVM = SVM.predict(Xtest)\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions_SVM, Test_y).ravel()\n",
    "    k = cohens_kappa(tp,fp,fn,tn)\n",
    "    return accuracy_score(predictions_SVM, Test_y),precision_score(predictions_SVM, Test_y),recall_score(predictions_SVM, Test_y),k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f180ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg1(s,tokenizer, Xtrain, Xtest, Train_y, Test_y):\n",
    "    set_random_seed(seed = s)\n",
    "    Log = linear_model.LogisticRegression(random_state = s, max_iter = 10000)\n",
    "    Log.fit(Xtrain,Train_y)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_Log = Log.predict(Xtest)\n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    #print(\"Logistic Regression Accuracy Score -> \",accuracy_score(predictions_Log, Test_y)*100)\n",
    "    # Confusion Matrix\n",
    "    #print(\"Logistic Regression Confusion Matrix -> \",confusion_matrix(predictions_Log, Test_y))\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions_Log, Test_y).ravel()\n",
    "    k = cohens_kappa(tp,fp,fn,tn)\n",
    "    return accuracy_score(predictions_Log, Test_y),precision_score(predictions_Log, Test_y),recall_score(predictions_Log, Test_y),k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b655d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randFor1(s,tokenizer, Xtrain, Xtest, Train_y, Test_y):\n",
    "    set_random_seed(seed = s)\n",
    "    RF = ensemble.RandomForestClassifier(n_estimators =400,criterion=\"entropy\",random_state =s)\n",
    "    RF.fit(Xtrain,Train_y)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_RF = RF.predict(Xtest)\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions_RF, Test_y).ravel()\n",
    "    k = cohens_kappa(tp,fp,fn,tn)\n",
    "    return accuracy_score(predictions_RF, Test_y),precision_score(predictions_RF, Test_y),recall_score(predictions_RF, Test_y),k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "befb4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN1(s,tokenizer, Xtrain, Xtest, Train_y, Test_y):\n",
    "    set_random_seed(seed = s)\n",
    "    kNN = neighbors.KNeighborsClassifier(n_neighbors = 3, p = 1)\n",
    "    kNN.fit(Xtrain,Train_y)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_kNN = kNN.predict(Xtest)\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions_kNN, Test_y).ravel()\n",
    "    k = cohens_kappa(tp,fp,fn,tn)\n",
    "    return accuracy_score(predictions_kNN, Test_y),precision_score(predictions_kNN, Test_y),recall_score(predictions_kNN, Test_y),k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "788e78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Accuracy:\n",
      "0.9306930693069306\n",
      "0.021235258009432864\n",
      "Precision:\n",
      "0.7204469264395734\n",
      "0.11282704908783875\n",
      "Recall:\n",
      "0.7878339869409916\n",
      "0.10399909170507902\n",
      "Kappa:\n",
      "0.7059600582153376\n",
      "0.09081095798550105\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "prec = []\n",
    "rec = []\n",
    "kap = []\n",
    "for seed in range(40):\n",
    "    tokenizer, Xtrain, Xtest, Train_y, Test_y = make_split(seed)\n",
    "    a,p,r,k = svm1(seed,tokenizer, Xtrain, Xtest, Train_y, Test_y)\n",
    "    acc.append(a)\n",
    "    prec.append(p)\n",
    "    rec.append(r)\n",
    "    kap.append(k)\n",
    "print(\"SVM\")\n",
    "print(\"Accuracy:\")\n",
    "print(np.mean(acc))\n",
    "print(np.std(acc))\n",
    "print(\"Precision:\")\n",
    "print(np.mean(prec))\n",
    "print(np.std(prec))\n",
    "print(\"Recall:\")\n",
    "print(np.mean(rec))\n",
    "print(np.std(rec))\n",
    "print(\"Kappa:\")\n",
    "print(np.mean(kap))\n",
    "print(np.std(kap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75f727f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy:\n",
      "0.9386138613861386\n",
      "0.02376237623762374\n",
      "Precision:\n",
      "0.6031111943611943\n",
      "0.13795512869445656\n",
      "Recall:\n",
      "0.9277561327561328\n",
      "0.07828176796882683\n",
      "Kappa:\n",
      "0.6892857129011503\n",
      "0.11728674040719023\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "prec = []\n",
    "rec = []\n",
    "kap = []\n",
    "for seed in range(20):\n",
    "    tokenizer, Xtrain, Xtest, Train_y, Test_y = make_split(seed)\n",
    "    a,p,r,k = logreg1(seed,tokenizer, Xtrain, Xtest, Train_y, Test_y)\n",
    "    acc.append(a)\n",
    "    prec.append(p)\n",
    "    rec.append(r)\n",
    "    kap.append(k)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy:\")\n",
    "print(np.mean(acc))\n",
    "print(np.std(acc))\n",
    "print(\"Precision:\")\n",
    "print(np.mean(prec))\n",
    "print(np.std(prec))\n",
    "print(\"Recall:\")\n",
    "print(np.mean(rec))\n",
    "print(np.std(rec))\n",
    "print(\"Kappa:\")\n",
    "print(np.mean(kap))\n",
    "print(np.std(kap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1f3e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy:\n",
      "0.9336633663366335\n",
      "0.02406979362602616\n",
      "Precision:\n",
      "0.5811957486957486\n",
      "0.13790329516493025\n",
      "Recall:\n",
      "0.8950919913419911\n",
      "0.0941821189247829\n",
      "Kappa:\n",
      "0.6615060793716765\n",
      "0.12524926533131273\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "prec = []\n",
    "rec = []\n",
    "kap = []\n",
    "for seed in range(20):\n",
    "    tokenizer, Xtrain, Xtest, Train_y, Test_y = make_split(seed)\n",
    "    a,p,r,k = randFor1(seed,tokenizer, Xtrain, Xtest, Train_y, Test_y)\n",
    "    acc.append(a)\n",
    "    prec.append(p)\n",
    "    rec.append(r)\n",
    "    kap.append(k)\n",
    "print(\"Random Forest\")\n",
    "print(\"Accuracy:\")\n",
    "print(np.mean(acc))\n",
    "print(np.std(acc))\n",
    "print(\"Precision:\")\n",
    "print(np.mean(prec))\n",
    "print(np.std(prec))\n",
    "print(\"Recall:\")\n",
    "print(np.mean(rec))\n",
    "print(np.std(rec))\n",
    "print(\"Kappa:\")\n",
    "print(np.mean(kap))\n",
    "print(np.std(kap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c932fc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k Nearest neighbors\n",
      "0.8747524752475249\n",
      "0.026983604108735938\n",
      "0.3215037046287047\n",
      "0.1218375310478276\n",
      "0.5947691197691197\n",
      "0.16264053796702152\n",
      "0.3402165421438634\n",
      "0.11328814244286568\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "prec = []\n",
    "rec = []\n",
    "kap = []\n",
    "for seed in range(20):\n",
    "    tokenizer, Xtrain, Xtest, Train_y, Test_y = make_split(seed)\n",
    "    a,p,r,k = KNN1(seed,tokenizer, Xtrain, Xtest, Train_y, Test_y)\n",
    "    acc.append(a)\n",
    "    prec.append(p)\n",
    "    rec.append(r)\n",
    "    kap.append(k)\n",
    "print(\"k Nearest neighbors\")\n",
    "print(np.mean(acc))\n",
    "print(np.std(acc))\n",
    "print(np.mean(prec))\n",
    "print(np.std(prec))\n",
    "print(np.mean(rec))\n",
    "print(np.std(rec))\n",
    "print(np.mean(kap))\n",
    "print(np.std(kap))\n",
    "#svm1, logreg1, randFor1, KNN1, neural_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96627dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "0.9143564356435645\n",
      "0.022200086460176873\n",
      "0.5741396103896104\n",
      "0.12888349170268948\n",
      "0.7464858058608058\n",
      "0.09649696926779397\n",
      "0.5923215914659752\n",
      "0.10125936561133451\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "prec = []\n",
    "rec = []\n",
    "kap = []\n",
    "for seed in range(20):\n",
    "    tokenizer, Xtrain, Xtest, Train_y, Test_y = make_split(seed)\n",
    "    a,p,r,k = naivebayes1(seed,tokenizer, Xtrain, Xtest, Train_y, Test_y)\n",
    "    acc.append(a)\n",
    "    prec.append(p)\n",
    "    rec.append(r)\n",
    "    kap.append(k)\n",
    "print(\"Naive Bayes\")\n",
    "print(np.mean(acc))\n",
    "print(np.std(acc))\n",
    "print(np.mean(prec))\n",
    "print(np.std(prec))\n",
    "print(np.mean(rec))\n",
    "print(np.std(rec))\n",
    "print(np.mean(kap))\n",
    "print(np.std(kap))\n",
    "#svm1, logreg1, randFor1, KNN1, neural_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7793a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523e806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
